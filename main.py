import os
import shutil
import streamlit as st
import pdfplumber
import zipfile
import csv
from docx import Document
import patoolib  # æ·»åŠ patoolibåº“ä»¥å¤„ç†å¤šç§å‹ç¼©æ ¼å¼


# å®šä¹‰å‡½æ•°ï¼Œè¯»å–å¹¶ç»Ÿè®¡PDFæ–‡ä»¶ä¸­æŒ‡å®šè¯è¯­çš„ä¸ªæ•°
def count_word_in_pdf(file_path, word):
    count = 0
    try:
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    count += text.count(word)
    except Exception as e:
        st.error(f"Error reading PDF file {file_path}: {e}")
    return count


# å®šä¹‰å‡½æ•°ï¼Œè¯»å–å¹¶ç»Ÿè®¡TXTæ–‡ä»¶ä¸­æŒ‡å®šè¯è¯­çš„ä¸ªæ•°
def count_word_in_txt(file_path, word):
    count = 0
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            text = file.read()
            count = text.count(word)
    except Exception as e:
        st.error(f"Error reading TXT file {file_path}: {e}")
    return count


# å®šä¹‰å‡½æ•°ï¼Œè¯»å–å¹¶ç»Ÿè®¡CSVæ–‡ä»¶ä¸­æŒ‡å®šè¯è¯­çš„ä¸ªæ•°
def count_word_in_csv(file_path, word):
    count = 0
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            reader = csv.reader(file)
            for row in reader:
                row_text = ','.join(row)
                count += row_text.count(word)
    except Exception as e:
        st.error(f"Error reading CSV file {file_path}: {e}")
    return count


# å®šä¹‰å‡½æ•°ï¼Œè¯»å–å¹¶ç»Ÿè®¡Wordæ–‡ä»¶ä¸­æŒ‡å®šè¯è¯­çš„ä¸ªæ•°
def count_word_in_docx(file_path, word):
    count = 0
    try:
        doc = Document(file_path)
        for paragraph in doc.paragraphs:
            count += paragraph.text.count(word)
    except Exception as e:
        st.error(f"Error reading DOCX file {file_path}: {e}")
    return count


# å®šä¹‰å‡½æ•°ï¼Œéå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼Œå¹¶ç»Ÿè®¡æŒ‡å®šè¯è¯­çš„æ€»æ•°
def count_word_in_folder(folder_path, word):
    word_count = 0
    results = []
    seen_files = set()
    for root, dirs, files in os.walk(folder_path):
        for filename in files:
            if filename in seen_files:
                continue
            seen_files.add(filename)
            file_path = os.path.join(root, filename)
            if filename.endswith('.pdf'):
                count = count_word_in_pdf(file_path, word)
            elif filename.endswith('.txt'):
                count = count_word_in_txt(file_path, word)
            elif filename.endswith('.csv'):
                count = count_word_in_csv(file_path, word)
            elif filename.endswith('.docx'):
                count = count_word_in_docx(file_path, word)
            else:
                continue
            word_count += count
            results.append((filename, count))
    return word_count, results


# è§£å‹ä¸Šä¼ çš„æ–‡ä»¶å¤¹ï¼Œå¹¶å¤„ç†ä¹±ç é—®é¢˜
def unzip_and_filter_folders(zip_file, extract_to, file_type):
    if file_type == "zip":
        with zipfile.ZipFile(zip_file, 'r') as zip_ref:
            zip_ref.extractall(extract_to)
    elif file_type == "rar":
        patoolib.extract_archive(zip_file, outdir=extract_to)

    extracted_files = os.listdir(extract_to)

    normal_folders = []
    for folder in extracted_files:
        folder_path = os.path.join(extract_to, folder)
        if os.path.isdir(folder_path):
            normal_folders.append(folder_path)

    if len(normal_folders) == 0:
        st.error("æœªæ‰¾åˆ°æ­£å¸¸æ˜¾ç¤ºçš„æ–‡ä»¶å¤¹")
        return None

    return normal_folders[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ­£å¸¸æ–‡ä»¶å¤¹çš„è·¯å¾„


# å°è¯•å¤šç§ç¼–ç æ–¹æ¡ˆæ¥è§£ç æ–‡ä»¶å
def try_decode(filename):
    encodings = ['utf-8', 'gbk', 'latin1', 'cp437']
    for enc in encodings:
        try:
            return filename.encode('cp437', errors='ignore').decode(enc)
        except (UnicodeEncodeError, UnicodeDecodeError):
            continue
    return filename  # å¦‚æœè§£ç å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡ä»¶å


# Streamlit åº”ç”¨ç¨‹åº
def main():
    st.markdown("<h3 style='text-align: center; color: black;'>ğŸ“šåœ¨å¤šä¸ªæ–‡ä»¶é‡Œæ£€ç´¢æŸä¸ªè¯è¯­çš„ä¸ªæ•°</h3>",
                unsafe_allow_html=True)
    st.write('\n')
    st.write('\n')
    st.write('\n')
    st.write('\n')
    uploaded_file = st.file_uploader("è¯·é€‰æ‹©ä¸€ä¸ªåŒ…å«å¤šä¸ªæ–‡ä»¶çš„å‹ç¼©æ–‡ä»¶ã€zipæˆ–è€…rarã€‘", type=["zip", "rar"])
    word = st.text_input("è¯·è¾“å…¥è¦æ£€ç´¢çš„è¯è¯­:")
    search_button = st.button("æ£€ç´¢")

    if search_button and uploaded_file is not None:
        with st.spinner("æ­£åœ¨å¤„ç†..."):
            folder_path = "extracted_files"
            if not os.path.exists(folder_path):
                os.makedirs(folder_path)

            # æ£€æµ‹æ–‡ä»¶ç±»å‹
            file_type = uploaded_file.name.split(".")[-1]

            # è§£å‹å¹¶è¿‡æ»¤ZIP/RARæ–‡ä»¶
            normal_folder_path = unzip_and_filter_folders(uploaded_file, folder_path, file_type)

            if normal_folder_path:
                total_count, results = count_word_in_folder(normal_folder_path, word)
                st.write(f"æ€»å…±æ‰¾åˆ° '{word}' {total_count} æ¬¡")
                for filename, count in results:
                    decoded_filename = try_decode(filename)
                    st.write(f"æ–‡ä»¶: {decoded_filename}, åŒ…å« '{word}' {count} æ¬¡")

    # æ·»åŠ åˆ†å‰²çº¿å’Œç‰ˆæƒä¿¡æ¯ï¼Œå›ºå®šåœ¨é¡µé¢åº•éƒ¨
    st.markdown("""
    <style>
    .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        background-color: white;
        text-align: center;
        padding: 10px 0;
        border-top: 1px solid #ddd;
        font-family: KaiTi;
    }
    .email {
        font-family: KaiTi,Times New Roman;
    }
    </style>
    <div class="footer">
        Copyright Â© 2024-é•¿æœŸ ç‰ˆæƒæ‰€æœ‰ï¼šåå¸ˆæ²ˆå¨ï¼Œåœ¨ä½¿ç”¨ä¸­å¦‚æœæœ‰ä»»ä½•é—®é¢˜å¯ä»¥å‘é‚®ä»¶è‡³ï¼šsw@ccnu.edu.cn
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
